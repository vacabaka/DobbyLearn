# General Agent Profile
# A versatile configuration for general-purpose agent task execution
# Includes web browsing, code execution, file operations, and fundamental tools

# Default agent configurations
agents:
  # Atomizer: Fast decision-making with Gemini Flash
  atomizer:
    llm:
      model: openrouter/google/gemini-2.5-flash
      temperature: 0.0
      max_tokens: 8000
    # Load atomizer seed prompt and demos for improved task classification
    signature_instructions: "prompt_optimization.prompts.seed_prompts.atomizer_seed:ATOMIZER_PROMPT"
    demos: "prompt_optimization.prompts.seed_prompts.atomizer_seed:ATOMIZER_DEMOS"

  # Planner: Strategic planning with Gemini Flash
  planner:
    llm:
      model: openrouter/google/gemini-2.5-flash
      temperature: 0.1
      max_tokens: 32000
    # Load planner seed prompt and demos for improved task decomposition
    signature_instructions: "prompt_optimization.prompts.seed_prompts.planner_seed:PLANNER_PROMPT"
    demos: "prompt_optimization.prompts.seed_prompts.planner_seed:PLANNER_DEMOS"
    agent_config:
      max_subtasks: 12

  # Default Executor (fallback for unmapped task types)
  executor:
    llm:
      model: openrouter/anthropic/claude-sonnet-4.5
      temperature: 0.2
      max_tokens: 32000
    prediction_strategy: react
    # Load executor seed prompt and demos for improved task execution
    signature_instructions: "prompt_optimization.prompts.seed_prompts.executor_seed:EXECUTOR_PROMPT"
    demos: "prompt_optimization.prompts.seed_prompts.executor_seed:EXECUTOR_DEMOS"
    agent_config:
      max_executions: 10

    # Default fundamental toolkits
    toolkits:
      - class_name: E2BToolkit
        enabled: true
        toolkit_config:
          timeout: 600
          max_lifetime_hours: 23.5
          auto_reinitialize: true

      - class_name: WebSearchToolkit
        enabled: true
        toolkit_config:
          model: openrouter/openai/gpt-5-mini
          # No search_engine = OpenRouter native search
          max_results: 5
          search_context_size: medium
          temperature: 1.0  # Required for GPT-5 reasoning models
          max_tokens: 16000  # Required for GPT-5 reasoning models

      - class_name: FileToolkit
        enabled: true
        toolkit_config:
          enable_delete: false
          max_file_size: 10485760  # 10MB

      - class_name: CalculatorToolkit
        enabled: true

  # Aggregator: Synthesis with Gemini Flash
  aggregator:
    llm:
      model: openrouter/google/gemini-2.5-flash
      temperature: 0.0
      max_tokens: 32000
    # Load aggregator seed prompt for improved result synthesis
    signature_instructions: "prompt_optimization.prompts.seed_prompts.aggregator_seed:AGGREGATOR_PROMPT"
    demos: "prompt_optimization.prompts.seed_prompts.aggregator_seed:AGGREGATOR_DEMOS"

  # Verifier: Validation with Gemini Flash
  verifier:
    llm:
      model: openrouter/google/gemini-2.5-flash
      temperature: 0.0
      max_tokens: 16000
    # Load verifier seed prompt and demos for improved output validation
    signature_instructions: "prompt_optimization.prompts.seed_prompts.verifier_seed:VERIFIER_PROMPT"
    demos: "prompt_optimization.prompts.seed_prompts.verifier_seed:VERIFIER_DEMOS"

# Runtime configuration
runtime:
  max_depth: 6
  verbose: true
  enable_logging: true
  log_level: INFO
  timeout: 120

# Resilience
resilience:
  retry:
    enabled: true
    max_attempts: 5
    strategy: exponential_backoff
    base_delay: 2.0
    max_delay: 60.0

  circuit_breaker:
    enabled: true
    failure_threshold: 5
    recovery_timeout: 120.0
    half_open_max_calls: 3

  checkpoint:
    enabled: true
    storage_path: ${oc.env:ROMA_CHECKPOINT_PATH,.checkpoints}
    max_checkpoints: 20
    max_age_hours: 48.0
    compress_checkpoints: true
    verify_integrity: true

# Storage
storage:
  base_path: ${oc.env:STORAGE_BASE_PATH,/opt/sentient}
  max_file_size: 104857600  # 100MB

  postgres:
    enabled: ${oc.env:POSTGRES_ENABLED,true}
    connection_url: ${oc.env:DATABASE_URL,postgresql+asyncpg://localhost/roma_dspy}
    pool_size: 10
    max_overflow: 20

# Observability
observability:
  mlflow:
    enabled: ${oc.env:MLFLOW_ENABLED,false}
    tracking_uri: ${oc.env:MLFLOW_TRACKING_URI,http://mlflow:5000}
    experiment_name: ROMA-General-Agent
    log_traces: true
    log_compiles: true
    log_evals: true

# Logging
logging:
  level: ${oc.env:LOG_LEVEL,INFO}
  log_dir: ${oc.env:LOG_DIR,logs}
  console_format: detailed
  file_format: json
  serialize: true
  rotation: 500 MB
  retention: 90 days
  colorize: true
  backtrace: true
  diagnose: false
